{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46273a7e-4863-42ba-8b34-c642a0ac2350",
   "metadata": {},
   "source": [
    "# Exploring Good Stories with Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb5a94-8841-4497-a919-d99fe8b7d52a",
   "metadata": {},
   "source": [
    "In this exercise we will be using a dataset of artificially crafted (boring) stories. The goal is to see if we can improve them using prompts based on Bunn's guide to being a good writer. We are going to divide our narrative dimensions into two categories: Sequential and Global. Sequential address the issue of narrative progression, while global address issues that the entire story taken together communicates.\n",
    "\n",
    "Your job is to build a notebook that takes a story as input and then create a series of prompts to improve the story by getting the LLM to focus on the dimensions below. You must address all dimensions in your notebook. Test multiple stories and for each dimension assess the quality of the LLM's ability to model that concept. Discuss strengths and weaknesses of the model and use examples to support your point. You won't be able to discuss all dimensions in your write-up so be focused. Submit your notebook along with your report this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a466c8-8b7d-492e-8660-715e1bd73d5d",
   "metadata": {},
   "source": [
    "## Sequential Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816b552-54f9-482f-b6af-43ac22c7b332",
   "metadata": {},
   "source": [
    "1. Set the scene\n",
    "2. Inciting incident\n",
    "3. Rising Action\n",
    "4. Climax (choose one)\n",
    "   - epiphany\n",
    "   - moral choice\n",
    "   - decisive action\n",
    "   - emotional release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285731f-66ad-4570-ac3c-0c717d7c3db5",
   "metadata": {},
   "source": [
    "## Global Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d494ae-1783-4025-b142-27dae25dca6b",
   "metadata": {},
   "source": [
    "1. Does it respect the three unities: single time, place, coherence of actions\n",
    "2. Do you feel like you are there?\n",
    "3. How much tension is there?\n",
    "4. Is there an element of strangeness?\n",
    "5. Is there a significant change or turning point?\n",
    "6. Is insight achieved?\n",
    "7. Is there a unified emotion governing the story?\n",
    "8. Are there meaningful shifts in valence (positive/negative)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416eab9-9801-464d-b0e0-998d19085760",
   "metadata": {},
   "source": [
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50707b-6197-4f5d-acc1-1df6a9ed9f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in ./.venv/lib/python3.13/site-packages (0.4.7)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: black in ./.venv/lib/python3.13/site-packages (25.1.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in ./.venv/lib/python3.13/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in ./.venv/lib/python3.13/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from black) (8.1.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./.venv/lib/python3.13/site-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: packaging>=22.0 in ./.venv/lib/python3.13/site-packages (from black) (24.2)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.13/site-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in ./.venv/lib/python3.13/site-packages (from black) (4.3.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama tqdm black pandas datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48956d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_story_from_csv(row_number, file_path):\n",
    "    \"\"\"\n",
    "    Reads a story from a specified row in a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - row_number: The row number from which to read the story.\n",
    "    - file_path: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - The story as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Check if the row number is valid\n",
    "        if row_number < 0 or row_number >= len(df):\n",
    "            raise ValueError(\"Invalid row number\")\n",
    "\n",
    "        # Define the story columns\n",
    "        story_columns = ['sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5']\n",
    "\n",
    "        # Concatenate the sentences to form the story\n",
    "        story = ' '.join(df.loc[row_number, story_columns].dropna().astype(str))\n",
    "\n",
    "        return story\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "story_files_path = \"ROCStories_winter2017 - ROCStories_winter2017.csv\"\n",
    "row_number = 0  # Replace with the desired row number\n",
    "\n",
    "source_story = read_story_from_csv(row_number, story_files_path)\n",
    "if source_story:\n",
    "    print(source_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing source story: David noticed he had\n",
      "Processed prompt 1 of 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first_two_words:  \u001b[38;5;66;03m# Handle empty source story\u001b[39;00m\n\u001b[32m     41\u001b[39m     first_two_words = [\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstory\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m.join(first_two_words)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdatetime\u001b[49m.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m df.to_csv(filename, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved output to file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Define text sources\n",
    "prompts = [\"Rewrite the following story to make it more engaging\"]\n",
    "prompt_number = 0\n",
    "\n",
    "# Set the model name\n",
    "model_name = \"llama3:8b\"\n",
    "\n",
    "# Initialize an empty list to store outputs\n",
    "outputs = []\n",
    "\n",
    "print(f\"Processing source story: {source_story[:20]}\")\n",
    "\n",
    "# Loop through each prompt\n",
    "for prompt_index, prompt in enumerate(prompts):\n",
    "    # Construct the prompt\n",
    "    rewrite_prompt = f\"Given the following source story: {source_story} please rewrite it according to the following instruction: {prompt}. Avoid any introduction, and directly output the generated text.\"\n",
    "    \n",
    "    # Generate text using the LLaMA model\n",
    "    response = ollama.chat(model=model_name, messages=[{\"role\": \"user\", \"content\": rewrite_prompt}])\n",
    "    generated_text = response[\"message\"][\"content\"]\n",
    "    \n",
    "    # Store the prompt and generated text\n",
    "    outputs.append({\n",
    "        \"Prompt\": prompt,\n",
    "        \"Generated Text\": generated_text\n",
    "    })\n",
    "    \n",
    "    # Display progress\n",
    "    print(f\"Processed prompt {prompt_index+1} of {len(prompts)}\")\n",
    "\n",
    "# Convert outputs to a DataFrame and save to CSV\n",
    "df = pd.DataFrame(outputs)\n",
    "\n",
    "# Extract first two words from the source story\n",
    "first_two_words = source_story.split()[:2]\n",
    "if not first_two_words:  # Handle empty source story\n",
    "    first_two_words = [\"default\", \"story\"]\n",
    "\n",
    "filename = f\"{'_'.join(first_two_words)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Saved output to file: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
