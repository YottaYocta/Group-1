{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfce3b5f-ee20-4293-925a-9608c8a4093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in ./.venv/lib/python3.13/site-packages (0.4.7)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: black in ./.venv/lib/python3.13/site-packages (25.1.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in ./.venv/lib/python3.13/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in ./.venv/lib/python3.13/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from black) (8.1.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./.venv/lib/python3.13/site-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: packaging>=22.0 in ./.venv/lib/python3.13/site-packages (from black) (24.2)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.13/site-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in ./.venv/lib/python3.13/site-packages (from black) (4.3.6)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.4-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.4-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.4 pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama tqdm black pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc4528-15d6-4bb8-aaf2-eae763915fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define text sources\n",
    "prompts = []\n",
    "prompt_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf98d03-bfdf-49ae-8bd8-71a8603da7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing source text: \n",
      "    The word cookie\n",
      "Processed style 1 of 10 for source 1 of 3\n",
      "Processed style 2 of 10 for source 1 of 3\n",
      "Processed style 3 of 10 for source 1 of 3\n",
      "Processed style 4 of 10 for source 1 of 3\n",
      "Processed style 5 of 10 for source 1 of 3\n",
      "Processed style 6 of 10 for source 1 of 3\n",
      "Processed style 7 of 10 for source 1 of 3\n",
      "Processed style 8 of 10 for source 1 of 3\n",
      "Processed style 9 of 10 for source 1 of 3\n",
      "Processed style 10 of 10 for source 1 of 3\n",
      "Saved output to file: The_word_20250317_154854.csv\n",
      "Processing source text: \n",
      "    Don't abuse our\n",
      "Processed style 1 of 10 for source 2 of 3\n",
      "Processed style 2 of 10 for source 2 of 3\n",
      "Processed style 3 of 10 for source 2 of 3\n",
      "Processed style 4 of 10 for source 2 of 3\n",
      "Processed style 5 of 10 for source 2 of 3\n",
      "Processed style 6 of 10 for source 2 of 3\n",
      "Processed style 7 of 10 for source 2 of 3\n",
      "Processed style 8 of 10 for source 2 of 3\n",
      "Processed style 9 of 10 for source 2 of 3\n",
      "Processed style 10 of 10 for source 2 of 3\n",
      "Saved output to file: Don't_abuse_20250317_155216.csv\n",
      "Processing source text: \n",
      "    We recommend no\n",
      "Processed style 1 of 10 for source 3 of 3\n",
      "Processed style 2 of 10 for source 3 of 3\n",
      "Processed style 3 of 10 for source 3 of 3\n",
      "Processed style 4 of 10 for source 3 of 3\n",
      "Processed style 5 of 10 for source 3 of 3\n",
      "Processed style 6 of 10 for source 3 of 3\n",
      "Processed style 7 of 10 for source 3 of 3\n",
      "Processed style 8 of 10 for source 3 of 3\n",
      "Processed style 9 of 10 for source 3 of 3\n",
      "Processed style 10 of 10 for source 3 of 3\n",
      "Saved output to file: We_recommend_20250317_155421.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Set the model name\n",
    "model_name = \"llama3:8b\"\n",
    "\n",
    "# Define the source story and instruction prompts\n",
    "source_story = \"Insert your source story here.\"\n",
    "instruction_prompts = [\n",
    "    \"Rewrite the story as a thriller.\",\n",
    "    \"Rewrite the story as a romance.\",\n",
    "    \"Rewrite the story as a science fiction tale.\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store outputs\n",
    "outputs = []\n",
    "\n",
    "print(f\"Processing source story: {source_story[:20]}\")\n",
    "\n",
    "# Loop through each instruction prompt\n",
    "for prompt_index, prompt in enumerate(instruction_prompts):\n",
    "    # Construct the prompt\n",
    "    rewrite_prompt = f\"Given the following source story: {source_story} please rewrite it according to the following instruction: {prompt}. Avoid any introduction, and directly output the generated text.\"\n",
    "    \n",
    "    # Generate text using the LLaMA model\n",
    "    response = ollama.chat(model=model_name, messages=[{\"role\": \"user\", \"content\": rewrite_prompt}])\n",
    "    generated_text = response[\"message\"][\"content\"]\n",
    "    \n",
    "    # Store the prompt and generated text\n",
    "    outputs.append({\n",
    "        \"Prompt\": prompt,\n",
    "        \"Generated Text\": generated_text\n",
    "    })\n",
    "    \n",
    "    # Display progress\n",
    "    print(f\"Processed prompt {prompt_index+1} of {len(instruction_prompts)}\")\n",
    "\n",
    "# Convert outputs to a DataFrame and save to CSV\n",
    "df = pd.DataFrame(outputs)\n",
    "\n",
    "# Extract first two words from the source story\n",
    "first_two_words = source_story.split()[:2]\n",
    "if not first_two_words:  # Handle empty source story\n",
    "    first_two_words = [\"default\", \"story\"]\n",
    "\n",
    "filename = f\"{'_'.join(first_two_words)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Saved output to file: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
